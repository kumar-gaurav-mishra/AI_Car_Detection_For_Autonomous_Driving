{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Yolov3\n",
    "\n",
    "![cover](https://bitmovin.com/wp-content/uploads/2019/08/Object_detection_Blog_Image_Q3_19.jpg)\n",
    "\n",
    "Object detection is a computer vision task that involves both localizing one or more objects within an image and classifying each object in the image.\n",
    "\n",
    "It is a challenging computer vision task that requires both successful object localization in order to locate and draw a bounding box around each object in an image, and object classification to predict the correct class of object that was localized.\n",
    "Yolo is a faster object detection algorithm in computer vision and first described by Joseph Redmon, Santosh Divvala, Ross Girshick and Ali Farhadi in ['You Only Look Once: Unified, Real-Time Object Detection'](https://arxiv.org/abs/1506.02640)\n",
    "\n",
    "This notebook implements an object detection based on a pre-trained model - [YOLOv3 Pre-trained Weights (yolov3.weights) (237 MB)](https://pjreddie.com/media/files/yolov3.weights). The model architecture is called a “DarkNet” and was originally loosely based on the VGG-16 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "# This line changes tensorflow log level and suppresses warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = make_yolov3_model()\n",
    "\n",
    "# Load the model weights\n",
    "weight_reader = WeightReader(\"./model/yolov3.weights\")\n",
    "\n",
    "# Set model weights into the model\n",
    "weight_reader.load_weights(model)\n",
    "\n",
    "# save model to file\n",
    "model.save(\"./model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_filename = \"./images/traffic.jpg\"\n",
    "_image, image_w, image_h = load_and_preprocess_image(\n",
    "    photo_filename, [IMAGE_WIDTH, IMAGE_HEIGHT]\n",
    ")\n",
    "plt.imshow(_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.expand_dims(_image, 0)\n",
    "yhat = model.predict(image)\n",
    "print([a.shape for a in yhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    \"\"\"\n",
    "    Objects of boxes. (xmin,ymin) represents the upleft coordinate of the box while (xmax,ymax) means downright one.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness=None, classes=None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def decode_netout(netout, anchors, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2] = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:] = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\n",
    "    for i in range(grid_h * grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            # if(objectness.all() <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w  # center position, unit: image width\n",
    "            y = (row + y) / grid_h  # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w  # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h  # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(\n",
    "                x - w / 2, y - h / 2, x + w / 2, y + h / 2, objectness, classes\n",
    "            )\n",
    "            boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [\n",
    "    [116, 90, 156, 198, 373, 326],\n",
    "    [30, 61, 62, 45, 59, 119],\n",
    "    [10, 13, 16, 30, 33, 23],\n",
    "]\n",
    "boxes = list()\n",
    "\n",
    "\n",
    "for i in range(len(yhat)):\n",
    "\n",
    "    boxes += decode_netout(\n",
    "        yhat[i][0], anchors[i], net_h=IMAGE_HEIGHT, net_w=IMAGE_WIDTH\n",
    "    )\n",
    "\n",
    "\n",
    "for i in range(len(boxes)):\n",
    "\n",
    "    x_offset, x_scale = (IMAGE_WIDTH - IMAGE_WIDTH) / 2.0 / IMAGE_HEIGHT, float(\n",
    "        IMAGE_WIDTH\n",
    "    ) / IMAGE_WIDTH\n",
    "\n",
    "    y_offset, y_scale = (IMAGE_HEIGHT - IMAGE_HEIGHT) / 2.0 / IMAGE_HEIGHT, float(\n",
    "        IMAGE_HEIGHT\n",
    "    ) / IMAGE_HEIGHT\n",
    "\n",
    "    boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\n",
    "    boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\n",
    "    boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\n",
    "    boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_filter(boxes, labels, threshold_socre):\n",
    "    valid_boxes = []\n",
    "    valid_labels = []\n",
    "    valid_scores = []\n",
    "    for box in boxes:\n",
    "        for i in range(len(labels)):\n",
    "            if box.classes[i] > threshold_socre:\n",
    "                valid_boxes.append(box)\n",
    "                valid_labels.append(labels[i])\n",
    "                valid_scores.append(box.classes[i])\n",
    "\n",
    "    return (valid_boxes, valid_labels, valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = box_filter(boxes, labels, threshold_socre=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(filename, valid_data):\n",
    "\n",
    "    data = pyplot.imread(filename)\n",
    "    pyplot.imshow(data)\n",
    "    ax = pyplot.gca()\n",
    "    for i in range(len(valid_data[0])):\n",
    "        box = valid_data[0][i]\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color=\"white\")\n",
    "        ax.add_patch(rect)\n",
    "        print(valid_data[1][i], valid_data[2][i])\n",
    "        label = \"%s (%.3f)\" % (valid_data[1][i], valid_data[2][i])\n",
    "        pyplot.text(x1, y1, label, color=\"white\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(photo_filename, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_dic(valid_data):\n",
    "    data_dic = {}\n",
    "    (valid_boxes, valid_labels, valid_scores) = valid_data\n",
    "    for box, label, score in zip(valid_boxes, valid_labels, valid_scores):\n",
    "        if label not in data_dic:\n",
    "            data_dic[label] = [[score, box, \"kept\"]]\n",
    "        else:\n",
    "            data_dic[label].append([score, box, \"kept\"])\n",
    "\n",
    "    return data_dic\n",
    "\n",
    "\n",
    "dic = encoder_dic(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_box_coor(box):\n",
    "    return (box.xmin, box.ymin, box.xmax, box.ymax)\n",
    "\n",
    "\n",
    "def iou(box1, box2):\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = decode_box_coor(box1)\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = decode_box_coor(box2)\n",
    "\n",
    "    xi1 = max(box1_x1, box2_x1)\n",
    "    yi1 = max(box1_y1, box2_y1)\n",
    "    xi2 = min(box1_x2, box2_x2)\n",
    "    yi2 = min(box1_y2, box2_y2)\n",
    "    inter_width = xi2 - xi1\n",
    "    inter_height = yi2 - yi1\n",
    "    inter_area = max(inter_height, 0) * max(inter_width, 0)\n",
    "\n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def do_nms(data_dic, nms_thresh):\n",
    "    final_boxes, final_scores, final_labels = list(), list(), list()\n",
    "    for label in data_dic:\n",
    "        scores_boxes = sorted(data_dic[label], reverse=True)\n",
    "        for i in range(len(scores_boxes)):\n",
    "            if scores_boxes[i][2] == \"removed\":\n",
    "                continue\n",
    "            for j in range(i + 1, len(scores_boxes)):\n",
    "                if iou(scores_boxes[i][1], scores_boxes[j][1]) >= nms_thresh:\n",
    "                    scores_boxes[j][2] = \"removed\"\n",
    "\n",
    "        for e in scores_boxes:\n",
    "            print(label + \" \" + str(e[0]) + \" status: \" + e[2])\n",
    "            if e[2] == \"kept\":\n",
    "                final_boxes.append(e[1])\n",
    "                final_labels.append(label)\n",
    "                final_scores.append(e[0])\n",
    "\n",
    "    return (final_boxes, final_labels, final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = do_nms(dic, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(photo_filename, final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold=0.5):\n",
    "\n",
    "    max_boxes_tensor = K.variable(\n",
    "        max_boxes, dtype=\"int32\"\n",
    "    )  # tensor to be used in tf.image.non_max_suppression()\n",
    "    K.get_session().run(\n",
    "        tf.variables_initializer([max_boxes_tensor])\n",
    "    )  # initialize variable max_boxes_tensor\n",
    "    nms_indices = tf.image.non_max_suppression(\n",
    "        scores=scores,\n",
    "        boxes=boxes,\n",
    "        max_output_size=max_boxes,\n",
    "        iou_threshold=iou_threshold,\n",
    "    )\n",
    "\n",
    "    scores = K.gather(scores, nms_indices)\n",
    "    boxes = K.gather(boxes, nms_indices)\n",
    "    classes = K.gather(classes, nms_indices)\n",
    "\n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showresults(path):\n",
    "    _image, width, height = load_and_preprocess_image(path, [IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "    image = np.expand_dims(_image, 0)\n",
    "    yhat = model.predict(image)\n",
    "    boxes = list()\n",
    "    for j in range(len(yhat)):\n",
    "        boxes += decode_netout(\n",
    "            yhat[j][0], anchors[j], net_h=IMAGE_HEIGHT, net_w=IMAGE_WIDTH\n",
    "        )\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (IMAGE_WIDTH - IMAGE_WIDTH) / 2.0 / IMAGE_HEIGHT, float(\n",
    "            IMAGE_WIDTH\n",
    "        ) / IMAGE_WIDTH\n",
    "        y_offset, y_scale = (IMAGE_HEIGHT - IMAGE_HEIGHT) / 2.0 / IMAGE_HEIGHT, float(\n",
    "            IMAGE_HEIGHT\n",
    "        ) / IMAGE_HEIGHT\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    valid_data = box_filter(boxes, labels, threshold_socre=0.6)\n",
    "    dic = encoder_dic(valid_data)\n",
    "    final_data = do_nms(dic, 0.7)\n",
    "    draw_boxes(path, final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showresults(\"./images/zebra.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showresults(\"./images/kangaroo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
